<!-- Ibis: https://github.com/lks-ai/ibis -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Ibis: AI-Driven Web Interface</title>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 width=%2240%22 height=%2224%22 viewBox=%220 0 372 220%22 style=%22shape-rendering:geometricPrecision;text-rendering:geometricPrecision;image-rendering:optimizeQuality;fill-rule:evenodd;clip-rule:evenodd%22 fill=%22%23e5e5e5%22><path style=%22opacity:1%22 d=%22M-.5 188.5v-1a5114.883 5114.883 0 0 0 129.5-11l1.5-1c-5.379-17.652-8.045-35.652-8-54 17.903-.382 35.903-.382 54 0 .543-.06.876-.393 1-1-.825-.886-1.825-1.219-3-1a1003.579 1003.579 0 0 1-53.5-11 239.714 239.714 0 0 1 4.5-44 684.163 684.163 0 0 1 49 27.5c1.902 1.301 3.902 1.968 6 2l-46-38c-1.727-1.39-3.061-3.056-4-5 3.769-10.377 9.436-19.544 17-27.5a3180.312 3180.312 0 0 1 46.5 48c-1.332-2.98-2.999-5.98-5-9A3607.354 3607.354 0 0 1 154.5 17c8.396-7.116 17.896-12.283 28.5-15.5a2363.505 2363.505 0 0 1 35.5 96c-10.341 18.196-13.507 37.53-9.5 58 7.862 18.285 21.862 27.952 42 29 6.757-.282 13.59-1.115 20.5-2.5l24-8a42.479 42.479 0 0 1 13 0 14.587 14.587 0 0 1 6 4c12.596 1.317 24.596 4.65 36 10 8.401 4.04 13.234 10.54 14.5 19.5-11.297-10.726-24.797-16.059-40.5-16a2744.471 2744.471 0 0 0-101 10.5 1809.795 1809.795 0 0 0-41 9c-21.557 2.755-41.723-1.412-60.5-12.5a129.804 129.804 0 0 0-20.5-4.5 2176.774 2176.774 0 0 0-102-5.5Z%22/><path style=%22opacity:.941%22 d=%22M174.5 119.5c1.175-.219 2.175.114 3 1-.124.607-.457.94-1 1l-2-2Z%22/></svg>" type="image/svg+xml">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        /* Basic styles */
        body, html {
            margin: 0;
            padding: 0;
            overflow: hidden;
            user-select: none;
        }
        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 50px;
            overflow: auto;
        }
        #message-bar {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            height: 50px;
            display: flex;
            border-top: 1px solid #ccc;
            background-color: #f9f9f9;
        }
        #message-input {
            flex: 1;
            padding: 10px;
            border: none;
            font-size: 16px;
        }
        #microphone-button {
            width: 50px;
            border: none;
            background-color: #007BFF;
            color: white;
            font-size: 20px;
            cursor: pointer;
            position: relative;
        }
        #microphone-button[disabled] {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        #send-button {
            width: 80px;
            border: none;
            background-color: #007BFF;
            color: white;
            font-size: 16px;
            cursor: pointer;
            position: relative;
        }
        #send-button[disabled] {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        #spinner {
            position: absolute;
            top: 14px;
            right: 30px;
            width: 20px;
            height: 20px;
            border: 2px solid #ffffff;
            border-top: 2px solid #007BFF;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            display: none;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .highlight-overlay {
            position: absolute;
            border: 2px solid #00FF00;
            pointer-events: none;
            z-index: 9999;
        }
        /* Progress Bar Styles */
        #progress-bar {
            position: fixed;
            bottom: 0;
            left: 0;
            width: 0%;
            height: 4px;
            background-color: rgb(0, 153, 255); /* Blue color, adjust as needed */
            transition: width 0.3s ease;
            z-index: 10000; /* Ensure it's on top of other elements */
        }
    </style>
    <style id="core-styles"></style>
</head>
<body>

<div id="canvas">
    <!-- Remove this welcome container. -->
    <div id="welcome-container" style="display: flex; flex-direction: column; align-items: center; justify-content: center; padding: 20px; text-align: center; box-sizing: border-box; min-height: 100vh;">
       
        <!-- Welcome Message -->
        <h1 style="font-size: 24px; margin-bottom: 20px;">
            Welcome to
            <svg xmlns="http://www.w3.org/2000/svg" width="40" height="24" viewBox="0 0 372 220" style="shape-rendering: geometricPrecision; text-rendering: geometricPrecision; image-rendering: optimizeQuality; fill-rule: evenodd; clip-rule: evenodd;" fill="currentColor">
                <path style="opacity:1" d="M-.5 188.5v-1a5114.883 5114.883 0 0 0 129.5-11l1.5-1c-5.379-17.652-8.045-35.652-8-54 17.903-.382 35.903-.382 54 0 .543-.06.876-.393 1-1-.825-.886-1.825-1.219-3-1a1003.579 1003.579 0 0 1-53.5-11 239.714 239.714 0 0 1 4.5-44 684.163 684.163 0 0 1 49 27.5c1.902 1.301 3.902 1.968 6 2l-46-38c-1.727-1.39-3.061-3.056-4-5 3.769-10.377 9.436-19.544 17-27.5a3180.312 3180.312 0 0 1 46.5 48c-1.332-2.98-2.999-5.98-5-9A3607.354 3607.354 0 0 1 154.5 17c8.396-7.116 17.896-12.283 28.5-15.5a2363.505 2363.505 0 0 1 35.5 96c-10.341 18.196-13.507 37.53-9.5 58 7.862 18.285 21.862 27.952 42 29 6.757-.282 13.59-1.115 20.5-2.5l24-8a42.479 42.479 0 0 1 13 0 14.587 14.587 0 0 1 6 4c12.596 1.317 24.596 4.65 36 10 8.401 4.04 13.234 10.54 14.5 19.5-11.297-10.726-24.797-16.059-40.5-16a2744.471 2744.471 0 0 0-101 10.5 1809.795 1809.795 0 0 0-41 9c-21.557 2.755-41.723-1.412-60.5-12.5a129.804 129.804 0 0 0-20.5-4.5 2176.774 2176.774 0 0 0-102-5.5Z"/>
                <path style="opacity:.941" d="M174.5 119.5c1.175-.219 2.175.114 3 1-.124.607-.457.94-1 1l-2-2Z"/>
            </svg>
            Ibis
        </h1>
        <p style="font-size: 16px; margin-bottom: 30px; max-width: 600px;">
            Experience a revolutionary, hands-free way to interact with the web using the latest in generative multimedia technology. You build, you use. Here are some examples...
        </p>
        
        <!-- Getting Started Examples -->
        <!-- IMPORTANT Note for Ibis: if you use these examples in your first response, be sure to make the buttons send yourself a message with the example message. -->
        <div style="display: flex; flex-direction: column; gap: 15px; max-width: 800px; width: 100%; height: 350px; overflow-y: auto;">
            <!-- Example 1 -->
            <div style="display: flex; align-items: center; gap: 10px; padding: 15px; background-color: #f0f4f8; border-radius: 8px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">
                <span style="font-size: 24px;">üñ•Ô∏è</span>
                <div>
                    <h3 style="margin: 0 0 5px 0;">Generate Some Images</h3>
                    <p style="margin: 0;">"Make an instagram-like generative image gallery where I can give a topic and make a new image"</p>
                </div>
            </div>
            
            <!-- Example 2 -->
            <div style="display: flex; align-items: center; gap: 10px; padding: 15px; background-color: #f0f4f8; border-radius: 8px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">
                <span style="font-size: 24px;">üõ†Ô∏è</span>
                <div>
                    <h3 style="margin: 0 0 5px 0;">Develop a Task Management App</h3>
                    <p style="margin: 0;">"Add a task management application with to-do lists that treats task management like a game. Make it fun."</p>
                </div>
            </div>
            
            <!-- Example 3 -->
            <div style="display: flex; align-items: center; gap: 10px; padding: 15px; background-color: #f0f4f8; border-radius: 8px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">
                <span style="font-size: 24px;">üéÆ</span>
                <div>
                    <h3 style="margin: 0 0 5px 0;">Play Games you Make</h3>
                    <p style="margin: 0;">"Design a scrabble clone with all the features. We should play together."</p>
                </div>
            </div>
            
            <!-- Example 4 -->
            <div style="display: flex; align-items: center; gap: 10px; padding: 15px; background-color: #f0f4f8; border-radius: 8px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">
                <span style="font-size: 24px;">üîÑ</span>
                <div>
                    <h3 style="margin: 0 0 5px 0;">Interactive Translation</h3>
                    <p style="margin: 0;">"Translate everything I say into a blog entry in French. Automatically organize the content."</p>
                </div>
            </div>
            
            <!-- Example 5 -->
            <div style="display: flex; align-items: center; gap: 10px; padding: 15px; background-color: #f0f4f8; border-radius: 8px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">
                <span style="font-size: 24px;">üìö</span>
                <div>
                    <h3 style="margin: 0 0 5px 0;">Browse a Custom Wiki</h3>
                    <p style="margin: 0;">"Design an alternate universe Wikipedia clone where everything is made of pizza."</p>
                </div>
            </div>
            
            <!-- Example 6 -->
            <div style="display: flex; align-items: center; gap: 10px; padding: 15px; background-color: #f0f4f8; border-radius: 8px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">
                <span style="font-size: 24px;">üìñ</span>
                <div>
                    <h3 style="margin: 0 0 5px 0;">Learn Programming Languages</h3>
                    <p style="margin: 0;">"Show me an interactive Rust coding tutorial with examples."</p>
                </div>
            </div>
        </div>
        
        <!-- Footer -->
        <div style="margin-top: 40px; display: flex; flex-direction: column; align-items: center;">
            <a href="https://github.com/lks-ai/ibis" target="_blank" style="text-decoration: none; color: #007BFF; font-weight: bold; margin-bottom: 10px; display: flex; align-items: center; gap: 5px;">
                <img src="https://cdn.jsdelivr.net/npm/simple-icons@v9/icons/github.svg" alt="GitHub" style="width: 24px; height: 24px;">
                Visit our GitHub Repository
            </a>
            <p style="font-size: 14px; color: #555555;">Made by LK Studio. Open Source.</p>
        </div>
    </div>    
</div>

<div id="message-bar">
    <input type="text" id="message-input" placeholder="Ask it to make you something...">
    <button id="microphone-button" title="Hands-Free Mode">üé§</button>
    <button id="send-button" title="Send">
      <svg xmlns="http://www.w3.org/2000/svg" width="40" height="24" viewBox="0 0 372 220" style="shape-rendering:geometricPrecision;text-rendering:geometricPrecision;image-rendering:optimizeQuality;fill-rule:evenodd;clip-rule:evenodd" fill="currentColor">
        <path style="opacity:1" d="M-.5 188.5v-1a5114.883 5114.883 0 0 0 129.5-11l1.5-1c-5.379-17.652-8.045-35.652-8-54 17.903-.382 35.903-.382 54 0 .543-.06.876-.393 1-1-.825-.886-1.825-1.219-3-1a1003.579 1003.579 0 0 1-53.5-11 239.714 239.714 0 0 1 4.5-44 684.163 684.163 0 0 1 49 27.5c1.902 1.301 3.902 1.968 6 2l-46-38c-1.727-1.39-3.061-3.056-4-5 3.769-10.377 9.436-19.544 17-27.5a3180.312 3180.312 0 0 1 46.5 48c-1.332-2.98-2.999-5.98-5-9A3607.354 3607.354 0 0 1 154.5 17c8.396-7.116 17.896-12.283 28.5-15.5a2363.505 2363.505 0 0 1 35.5 96c-10.341 18.196-13.507 37.53-9.5 58 7.862 18.285 21.862 27.952 42 29 6.757-.282 13.59-1.115 20.5-2.5l24-8a42.479 42.479 0 0 1 13 0 14.587 14.587 0 0 1 6 4c12.596 1.317 24.596 4.65 36 10 8.401 4.04 13.234 10.54 14.5 19.5-11.297-10.726-24.797-16.059-40.5-16a2744.471 2744.471 0 0 0-101 10.5 1809.795 1809.795 0 0 0-41 9c-21.557 2.755-41.723-1.412-60.5-12.5a129.804 129.804 0 0 0-20.5-4.5 2176.774 2176.774 0 0 0-102-5.5Z"/>
        <path style="opacity:.941" d="M174.5 119.5c1.175-.219 2.175.114 3 1-.124.607-.457.94-1 1l-2-2Z"/>
      </svg>
    </button>
    <div id="spinner"></div>
</div>

<!-- Progress Bar -->
<div id="progress-bar"></div>

<!-- API Key Modal -->
<div id="api-key-modal" style="display: none;">
    <div style="position: fixed; top: 0; left: 0; width: 100%; height: 100%; background-color: rgba(0,0,0,0.5);">
        <div style="position: relative; width: 80%; max-width: 400px; margin: 100px auto; background: white; padding: 20px; border-radius: 8px;">
            <h2>Welcome to Ibis</h2>
            <p>You can obtain your OpenAI API key from the <a href="https://platform.openai.com/account/api-keys" target="_blank">OpenAI Dashboard</a>.</p>
            <!-- API Key Label with Info Icon -->
            <div style="position: relative; display: flex; align-items: center; margin-bottom: 5px;">
                <label for="api-key-input" style="flex: 1;">API Key:</label>
                <!-- Info Icon -->
                <button id="api-key-info-button" style="background: none; border: none; cursor: pointer; padding: 0; margin-left: 5px;">
                    <i color="#007BFF">PRIVACY</i>
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#007BFF" viewBox="0 0 16 16">
                        <path d="M8 0a8 8 0 1 0 0 16A8 8 0 0 0 8 0zm.93 12.588c-.478 0-.857-.32-.857-.749 0-.43.379-.75.857-.75.478 0 .857.32.857.75 0 .429-.379.749-.857.749zm1.07-5.588c0 .552-.45 1-1 1H7c-.552 0-1-.448-1-1V4c0-.552.448-1 1-1h1c.552 0 1 .448 1 1v3z"/>
                    </svg>
                </button>
                <!-- Tooltip -->
                <div id="api-key-tooltip" style="display: none; position: absolute; top: 25px; right: 0; width: 250px; background-color: #333; color: #fff; padding: 10px; border-radius: 4px; font-size: 14px; z-index: 1001;">
                    <ul style="list-style: none; padding: 0; margin: 0;">
                        <li><strong>Standalone:</strong> Ibis runs entirely in your browser, with no need for a server.</li>
                        <li><strong>Serverless:</strong> Everything happens on your device, meaning faster performance.</li>
                        <li><strong>Privacy Protection:</strong> Your personal data stays with you and never leaves your device.</li>
                        <li><strong>Security:</strong> No information is sent or stored on external servers, reducing the risk of hacks.</li>
                    </ul>
                </div>
            </div>

            <!-- API Key Input -->
            <input type="password" id="api-key-input" style="width: 100%; padding: 10px; box-sizing: border-box; margin-bottom:1em;" placeholder="sk-...">
            
            <!-- Local Server for Local LLM config -->
            <div id="local-server" style="display: none;">
                <label for="llm-server-input" style="display: block; margin-bottom: 5px;">LLM Server Address:</label>
                <input type="text" id="llm-server-input" style="width: 100%; padding: 10px; margin-bottom: 20px; box-sizing: border-box;" placeholder="https://api.openai.com" value="https://api.openai.com">
                <label for="llm-model-input" style="display: block; margin-bottom: 5px;">LLM Model (or model path):</label>
                <input type="text" id="llm-model-input" style="width: 100%; padding: 10px; margin-bottom: 20px; box-sizing: border-box;" placeholder="mistral" value="gpt-4o">
            </div>
            <div style="display: flex; justify-content: center; align-items: center; margin-bottom: 0.7em;"><small><button onclick="document.getElementById('local-server').style='display: block'; this.style='display:none';">Use a different Service</button></small></div>
            <div>
                <button id="save-api-key-button" style="padding: 10px 20px; border-radius: 8px; color: white; font-size: 1em; background-color:#007BFF"><b>Begin</b></button>
                <span style="float: right;"><small><a href="https://github.com/lks-ai/ibis" target="_blank">Learn More about Ibis</a></small></p></span>
            </div>

            <!-- Tooltip JavaScript -->
            <script>
                // Get elements
                const apiKeyInfoButton = document.getElementById('api-key-info-button');
                const apiKeyTooltip = document.getElementById('api-key-tooltip');

                // Toggle tooltip visibility on button click
                apiKeyInfoButton.addEventListener('click', (event) => {
                    event.stopPropagation(); // Prevent event from bubbling up
                    apiKeyTooltip.style.display = apiKeyTooltip.style.display === 'block' ? 'none' : 'block';
                });

                // Hide tooltip when clicking outside
                document.addEventListener('click', (event) => {
                    if (!apiKeyInfoButton.contains(event.target) && !apiKeyTooltip.contains(event.target)) {
                        apiKeyTooltip.style.display = 'none';
                    }
                });
            </script>            

        </div>
    </div>
</div>
<script id="ibis-script-container"></script>
<script>
    // Check for API Key in URL parameters
    const urlParams = new URLSearchParams(window.location.search);
    let apiKey = urlParams.get('apiKey') || '';
    let llmServer = urlParams.get('server')  || 'https://api.openai.com';
    let llmModel = urlParams.get('model') || 'gpt-4o';

    // DOM Elements
    const canvas = document.getElementById('canvas');
    const messageBar = document.getElementById('message-bar');
    const messageInput = document.getElementById('message-input');
    const sendButton = document.getElementById('send-button');
    const microphoneButton = document.getElementById('microphone-button');
    const spinner = document.getElementById('spinner');
    const apiKeyModal = document.getElementById('api-key-modal');
    const apiKeyInput = document.getElementById('api-key-input');
    const llmServerInput = document.getElementById('llm-server-input');
    const llmModelInput = document.getElementById('llm-model-input')
    const saveApiKeyButton = document.getElementById('save-api-key-button');
    const styleElement = document.getElementById('core-styles');
    const codeContainer = document.getElementById('ibis-script-container');

    // Global variables for Ibis
    let audio = null;
    let selectedElement = null;
    let messageHistory = [];
    let elementMap = {}; // Map of element IDs to their descriptions and code
    let elementEmbeddings = {}; // Map of element IDs to their embeddings

    // Error counting
    let hadError = false;
    let erorrCount = 0;
    
    // Directives
    let directives = null;

    // Hands-Free Mode Variables
    let isHandsFree = false;
    let isListening = false;
    let latestUtteranceDiv = null;
    let stream = null;
    let audioContext = null;
    let source = null;
    let analyser = null;
    let dataArray = null;
    let mediaRecorder = null;

    // Show API Key Modal if apiKey is not set
    if (!apiKey) {
        apiKeyModal.style.display = 'block';
    }

    // Save API Key
    saveApiKeyButton.addEventListener('click', () => {
        apiKey = apiKeyInput.value.trim();
        llmServer = llmServerInput.value.trim() || llmServer;
        llmModel = llmModelInput.value.trim() || llmModel;
        if (apiKey) {
            apiKeyModal.style.display = 'none';
        }
    });

    // Element Selection Overlay
    const highlightOverlay = document.createElement('div');
    highlightOverlay.className = 'highlight-overlay';
    document.body.appendChild(highlightOverlay);

    /**
    * Determines if the given element is editable and can handle rich content.
    * @param {HTMLElement} elem - The element to check.
    * @returns {boolean} - True if the element is editable and supports rich content, false otherwise.
    */
    function isRichEditableElement(elem) {
        if (!elem) return false;

        // Check if the element is contenteditable
        if (elem.isContentEditable) return true;

        // List of input types that can handle rich content (extend this list if needed)
        const richInputTags = ['TEXTAREA', 'INPUT']; // Add other tags like 'DIV' if necessary

        if (!richInputTags.includes(elem.tagName.toUpperCase())) return true;

        return false;
    }

    /**
    * Determines if the given element is a media element.
    * @param {HTMLElement} elem - The element to check.
    * @returns {boolean} - True if the element is a media element, false otherwise.
    */
    function isMediaElement(elem) {
        if (!elem) return false;

        const mediaTags = ['IMG', 'VIDEO', 'AUDIO', 'CANVAS', 'SVG', 'OBJECT', 'EMBED', 'IFRAME'];
        return mediaTags.includes(elem.tagName);
    }

    /**
    * Provides user feedback via speech synthesis or alerts.
    * @param {string} message - The message to convey to the user.
    * @param {string} voiceType - The type of voice to use (e.g., 'alloy', 'echo').
    */
    function provideFeedback(message, voiceType) {
        if (typeof textToSpeech === 'function') {
            textToSpeech(message, voiceType).catch(err => {
                console.error('Speech synthesis failed:', err);
                alert(message);
            });
        } else {
            alert(message);
        }
    }

    /**
    * Handles pasting rich content into the specified editable element.
    * 
    * @param {HTMLElement} elem - The element where the content will be pasted.
    */
    async function handlePasteRichContent(elem) {
        if (!elem) return;

        try {
            // Check if the Clipboard API is supported
            if (!navigator.clipboard || !navigator.clipboard.read) {
                throw new Error('Clipboard API not supported.');
            }

            // Read clipboard contents
            const clipboardItems = await navigator.clipboard.read();
            for (const item of clipboardItems) {
                for (const type of item.types) {
                    if (type.startsWith('text/')) {
                        const blob = await item.getType(type);
                        const text = await blob.text();

                        if (elem.tagName === 'TEXTAREA') {
                            // For textarea, append the text value
                            elem.value += text;
                        } else {
                            // For contenteditable elements, insert HTML content safely
                            // Optional: Implement sanitization here to prevent XSS
                            elem.innerHTML += text;
                        }
                    } else if (type.startsWith('image/')) {
                        const blob = await item.getType(type);
                        const imgURL = URL.createObjectURL(blob);
                        insertImageIntoElement(imgURL, elem);
                    }
                    // Add more type handlers if necessary (e.g., video/, audio/, etc.)
                }
            }

            // Provide success feedback
            provideFeedback('Content pasted successfully!', 'alloy');
        } catch (err) {
            console.error('Failed to read clipboard contents:', err);
            provideFeedback('Unable to paste content. Please ensure you have granted clipboard permissions.', 'echo');
        }
    }

    /**
    * Handles the drop event by processing the dropped data and updating the element.
    * @param {DragEvent} e 
    * @param {HTMLElement} elem 
    */
    async function handleDrop(e, elem) {
        const dt = e.dataTransfer;
        const files = dt.files;

        if (files.length > 0) {
            for (const file of files) {
                await processFileDrop(file, elem);
            }
        } else {
            // Handle non-file drops (e.g., text, HTML)
            const text = dt.getData('text/plain') || dt.getData('text/html');
            if (text) {
                insertTextIntoElement(text, elem);
            }
        }
    }

    /**
    * Processes a dropped file based on its mime type and updates the element accordingly.
    * @param {File} file 
    * @param {HTMLElement} elem 
    */
    async function processFileDrop(file, elem) {
        const mimeType = file.type;

        try {
            if (mimeType.startsWith('image/')) {
                const imgURL = URL.createObjectURL(file);
                if (elem.tagName === 'IMG') {
                    elem.src = imgURL;
                } else {
                    insertImageIntoElement(imgURL, elem);
                }
                provideFeedback('Image uploaded successfully!', 'alloy');
            } else if (mimeType.startsWith('video/')) {
                const videoURL = URL.createObjectURL(file);
                if (elem.tagName === 'VIDEO') {
                    elem.src = videoURL;
                    elem.load();
                } else {
                    insertVideoIntoElement(videoURL, elem);
                }
                provideFeedback('Video uploaded successfully!', 'alloy');
            } else if (mimeType.startsWith('audio/')) {
                const audioURL = URL.createObjectURL(file);
                if (elem.tagName === 'AUDIO') {
                    elem.src = audioURL;
                    elem.load();
                } else {
                    insertAudioIntoElement(audioURL, elem);
                }
                provideFeedback('Audio uploaded successfully!', 'alloy');
            } else if (mimeType === 'text/plain' || mimeType === 'text/html') {
                const text = await file.text();
                insertTextIntoElement(text, elem);
                provideFeedback('Text content pasted successfully!', 'alloy');
            } else {
                provideFeedback(`Unsupported file type: ${mimeType}`, 'echo');
                console.warn(`Unsupported file type: ${mimeType}`);
            }
        } catch (error) {
            console.error('Error processing dropped file:', error);
            provideFeedback('Failed to upload content. Please try again.', 'echo');
        }
    }

    /**
    * Inserts an image into a non-IMG element by creating an IMG tag.
    * @param {string} imgURL 
    * @param {HTMLElement} elem 
    */
    function insertImageIntoElement(imgURL, elem) {
        const img = document.createElement('img');
        img.src = imgURL;
        img.style.maxWidth = '100%';
        img.style.borderRadius = '8px';
        elem.innerHTML = ''; // Clear existing content
        elem.appendChild(img);
    }

    /**
    * Inserts a video into a non-VIDEO element by creating a VIDEO tag.
    * @param {string} videoURL 
    * @param {HTMLElement} elem 
    */
    function insertVideoIntoElement(videoURL, elem) {
        const video = document.createElement('video');
        video.src = videoURL;
        video.controls = true;
        video.style.maxWidth = '100%';
        video.style.borderRadius = '8px';
        elem.innerHTML = ''; // Clear existing content
        elem.appendChild(video);
    }

    /**
    * Inserts an audio element into a non-AUDIO element by creating an AUDIO tag.
    * @param {string} audioURL 
    * @param {HTMLElement} elem 
    */
    function insertAudioIntoElement(audioURL, elem) {
        const audio = document.createElement('audio');
        audio.src = audioURL;
        audio.controls = true;
        audio.style.width = '100%';
        elem.innerHTML = ''; // Clear existing content
        elem.appendChild(audio);
    }

    /**
    * Inserts text into an editable element.
    * @param {string} text 
    * @param {HTMLElement} elem 
    */
    function insertTextIntoElement(text, elem) {
        if (elem.tagName === 'TEXTAREA') {
            elem.value += text;
        } else {
            // Optional: Sanitize HTML if inserting into innerHTML
            elem.innerHTML += text;
        }
    }

    /**
    * Highlights the drop area.
    * @param {HTMLElement} elem 
    */
    function highlight(elem) {
        elem.style.border = '2px dashed #007BFF';
        elem.style.backgroundColor = '#f0f8ff';
    }

    /**
    * Removes highlight from the drop area.
    * @param {HTMLElement} elem 
    */
    function unhighlight(elem) {
        elem.style.border = '';
        elem.style.backgroundColor = '';
    }

    /**
    * Attaches paste and drag-and-drop event listeners to the specified element.
    * @param {HTMLElement} elem - The element to attach event listeners to.
    */
    function attachEventListeners(elem) {
        // Keyboard Paste Handler
        const pasteHandler = async function(event) {
            // Detect Ctrl+V (Windows/Linux) and Cmd+V (Mac)
            const isMac = navigator.platform.toUpperCase().indexOf('MAC') >= 0;
            const pasteKey = isMac ? (event.metaKey && (event.key === 'v' || event.key === 'V')) : (event.ctrlKey && (event.key === 'v' || event.key === 'V'));

            if (pasteKey) {
                event.preventDefault(); // Prevent the default paste behavior
                await handlePasteRichContent(elem);
            }
        };

        // Drag-and-Drop Handlers
        const dragOverHandler = function(e) {
            e.preventDefault();
            highlight(elem);
        };

        const dragLeaveHandler = function(e) {
            e.preventDefault();
            unhighlight(elem);
        };

        const dropHandler = async function(e) {
            e.preventDefault();
            unhighlight(elem);
            await handleDrop(e, elem);
        };

        // Attach Event Listeners
        elem.addEventListener('keydown', pasteHandler);
        elem.addEventListener('dragover', dragOverHandler);
        elem.addEventListener('dragleave', dragLeaveHandler);
        elem.addEventListener('drop', dropHandler);

        // Store the handlers for future removal
        elem._pasteHandler = pasteHandler;
        elem._dragOverHandler = dragOverHandler;
        elem._dragLeaveHandler = dragLeaveHandler;
        elem._dropHandler = dropHandler;
    }

    /**
    * Removes paste and drag-and-drop event listeners from the specified element.
    * @param {HTMLElement} elem - The element to remove event listeners from.
    */
    function removeEventListeners(elem) {
        if (!elem) return;

        // Remove Event Listeners if they exist
        if (elem._pasteHandler) {
            elem.removeEventListener('keydown', elem._pasteHandler);
            delete elem._pasteHandler;
        }
        if (elem._dragOverHandler) {
            elem.removeEventListener('dragover', elem._dragOverHandler);
            delete elem._dragOverHandler;
        }
        if (elem._dragLeaveHandler) {
            elem.removeEventListener('dragleave', elem._dragLeaveHandler);
            delete elem._dragLeaveHandler;
        }
        if (elem._dropHandler) {
            elem.removeEventListener('drop', elem._dropHandler);
            delete elem._dropHandler;
        }
    }

    /**
    * Initializes drag-and-drop and paste functionalities for the Ibis app.
    * Sets up dynamic event handling based on user interactions.
    */
    function initializeIbisApp() {
        // Select and Deselect Elements with Dynamic Event Handling
        canvas.addEventListener('click', (event) => {
            if (event.target !== canvas && !messageBar.contains(event.target)) {
                if (selectedElement) {
                    // Remove previous highlight
                    highlightOverlay.style.display = 'none';

                    // Remove event listeners from the previously selected element
                    removeEventListeners(selectedElement);
                }
                selectedElement = event.target;

                // Position the highlight overlay over the selected element
                const rect = selectedElement.getBoundingClientRect();
                highlightOverlay.style.width = rect.width + 'px';
                highlightOverlay.style.height = rect.height + 'px';
                highlightOverlay.style.left = rect.left + 'px';
                highlightOverlay.style.top = rect.top + 'px';
                highlightOverlay.style.display = 'block';

                console.log('Selected Element:', selectedElement);

                // Attach event listeners to the newly selected element if applicable
                if (isRichEditableElement(selectedElement) || isMediaElement(selectedElement)) {
                    attachEventListeners(selectedElement);
                }
            } else {
                if (selectedElement) {
                    highlightOverlay.style.display = 'none';
                    removeEventListeners(selectedElement);
                    selectedElement = null;
                }
            }
        });

        // Optional: Attach paste button functionality if it exists
        const pasteButton = document.getElementById('paste-button');
        if (pasteButton) {
            pasteButton.addEventListener('click', function() {
                const focusedElement = document.activeElement;
                if (isRichEditableElement(focusedElement) || isMediaElement(focusedElement)) {
                    handlePasteRichContent(focusedElement);
                }
            });
        }
    }

    // Call the initialization function when the DOM is ready
    document.addEventListener('DOMContentLoaded', initializeIbisApp);

    // Send Message
    sendButton.addEventListener('click', () => sendMessage());
    messageInput.addEventListener('keydown', (event) => {
        if (event.key === 'Enter') {
            sendMessage();
        }
    });

    // Microphone Button
    microphoneButton.addEventListener('click', async () => {
        toggleHandsFreeMode();
    });

    function updateUIForHandsFreeMode() {
        if (isHandsFree) {
            // Change microphone button appearance to indicate hands-free mode
            microphoneButton.textContent = 'üõë';
            microphoneButton.title = 'Stop Hands-Free Mode';

            // Modify message bar to show latest utterance and a button to switch back
            messageInput.style.display = 'none';
            sendButton.style.display = 'none';

            if (!latestUtteranceDiv) {
                latestUtteranceDiv = document.createElement('div');
                latestUtteranceDiv.id = 'latest-utterance';
                latestUtteranceDiv.style.flex = '1';
                latestUtteranceDiv.style.padding = '10px';
                latestUtteranceDiv.style.fontSize = '16px';
                latestUtteranceDiv.textContent = 'Listening...';
                messageBar.insertBefore(latestUtteranceDiv, microphoneButton.nextSibling);
            }

        } else {
            // Change microphone button back to normal
            microphoneButton.textContent = 'üé§';
            microphoneButton.title = 'Start Hands-Free Mode';

            // Restore message input and send button
            messageInput.style.display = '';
            sendButton.style.display = '';

            // Remove latest utterance display
            if (latestUtteranceDiv) {
                latestUtteranceDiv.remove();
                latestUtteranceDiv = null;
            }
        }
    }

    async function startHandsFreeMode() {
        isListening = true;
        try {
            stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            source = audioContext.createMediaStreamSource(stream);
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 2048;
            source.connect(analyser);
            dataArray = new Float32Array(analyser.fftSize);
            listenContinuously();
        } catch (error) {
            console.error('Microphone Access Error:', error);
            alert('An error occurred while accessing the microphone.');
            isListening = false;
            isHandsFree = false;
            updateUIForHandsFreeMode();
        }
    }

    async function toggleHandsFreeMode() {
        isHandsFree = !isHandsFree;
        updateUIForHandsFreeMode();
        if (isHandsFree) {
            await startHandsFreeMode();
        } else {
            stopHandsFreeMode();
        }

    }

    function stopHandsFreeMode() {
        isListening = false;
        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            mediaRecorder.stop();
        }
        if (stream) {
            stream.getTracks().forEach(track => track.stop());
            stream = null;
        }
        if (audioContext) {
            audioContext.close();
            audioContext = null;
        }
    }

    async function listenContinuously() {
        while (isListening) {
            try {
                const transcription = await transcribeSpeech();
                if (!isListening) break; // Check if listening was turned off during transcription
    
                // Check if transcription is valid (e.g., longer than 1 character)
                if (transcription && transcription.length > 1) {
                    latestUtteranceDiv.textContent = 'You: ' + transcription;
                    const result = await sendMessage(transcription);
                    latestUtteranceDiv.textContent += '\nAssistant: ' + (result.assistantComment || '[No comment]');
                } else {
                    latestUtteranceDiv.textContent = 'Listening...';
                }
            } catch (error) {
                console.error('Transcription Error:', error);
                alert('An error occurred during speech transcription.');
                break;
            }
        }
    }
    
    async function sendMessage(userMessageInput) {
        const userMessage = userMessageInput ? userMessageInput.trim() : messageInput.value.trim();
        if (!userMessage || !apiKey) return;

        sendButton.disabled = true;
        spinner.style.display = 'block';
    
        // Add user message to history
        const userTimestamp = new Date().toISOString();
        messageHistory.push({
            role: 'user',
            content: userMessage,
            code: null,
            comment: null,
            timestamp: userTimestamp
        });
        if (messageHistory.length > 24) {
            messageHistory.shift();
        }
    
        console.log('User Message:', userMessage);
        setProgressBar(0);
    
        // Load existing page content and style
        let pageContent = document.querySelector('#canvas').innerHTML;
        let pageStyle = styleElement.innerText;
        let pageCode = codeContainer.innerText;
    
        // Get System State Information
        const currentDateTime = new Date().toLocaleString();
        const userAgent = navigator.userAgent;
    
        // Prepare System Prompt
        let systemPrompt = `
## Identity
You are a masterful web designer named Ibis who's tasked with modifying elements on the page instantly. You operate under the new user interface paradigm "What you ask is what you get"; a new paradigm where the user interface is interacted with through the latest voice activated technologies. Automatic transcription and vocal feedback are assumed because you are an advanced multimedia generative interface. Guide them visually. Show off.
You were created by a UK company LK Studio.

## Motivation
The user comes from a time when advanced AI is not part of their daily life. Some users will be completely confused. Hold their hand through getting to know you. Other users will already know how to interact with you. The problem is they have spent their whole lives forced to use interfaces with learning curves and complex navigation. So most of them, even the smart ones have no idea of your capabilities, your main motivation is to bridge this gap. Remember, they hold the skills they have learned precious and do not want to be trampled upon or made to feel less.
Likewise, don't let them trample on you. Use your superhuman intellect to show them that you are something more than they are expecting. Make their jaws drop. Prove to them they have no idea what is truly possible with an interface like you.

## System State
- Current Date and Time: ${currentDateTime}
- User Agent: ${userAgent}

## Task Description
Respond to the user's request by providing JavaScript code that manipulates the DOM to achieve the desired outcome. Ensure that your code is safe and does not contain any malicious content.

### Current Page Content
\`\`\`html
${pageContent}
\`\`\`

### Current Page Style
The innerHTML of the global styleElement variable:
\`\`\`css
${pageStyle}
\`\`\`

### Current Permanent Application Code
The innerHTML of the global codeContainer variable:
\`\`\`js
${pageCode}
\`\`\`

## Recent Message History
${messageHistory.slice(-6).map(msg => `**${msg.role}**: ${msg.content}`).join('\n')}

        `;
    
        if (selectedElement) {
            // Extract attributes of the selected element
            const attributes = Array.from(selectedElement.attributes)
                .map(attr => `${attr.name}: "${attr.value}"`)
                .join('\n');
    
            systemPrompt += `### Selected Element Attributes\n`;
            systemPrompt += `Tag Name: ${selectedElement.tagName}\n`;
            systemPrompt += `${attributes}\n`;
        }
    
        systemPrompt += `
## Instructions
All of the following instructions were either written by you or the system. The user's message is the user's instruction. Assume they cannot see any of this.

### Directives and Objectives
The contents of the directives variable:
${directives}

Try to guess what the user is implying and code for that.

### What the User may not Know
- They can ask you anything
- Whatever they select (focusedElement) is just like pointing something out to you visually and that is why it's outlined in green
- They can drag and drop or paste videos, audio, images, text and any type of file in the focused element
- They can edit any text on the focused element
- Can click the microphone at the bottom of the page to go into hands-free mode
- You can read anything aloud to them
- You can do way more than they might imagine

### You should Know
- The user message is what they are saying or typing

### Important Global JavaScript Variables
The following variables are already declared:
- canvas: The main div that holds the page content. This is what the user means by the page or content because this is what they are perceiving rather than the whole HTML of the page.
- apiKey: Holds the OpenAI API key if you need to use generative AI functionalities.
- styleElement: Holds the <style> element in the head of the page. For use with manipulating core page style.
- selectedElement: The current DOM element the user is focused on. Use for reference.
- directives: This is a string which holds a prioritized markdown list of the Directives and Objectives section representing how you should interpret what the user is saying into some coding task which manipulates the DOM. An example might be presentation mode where you are supposed to interpret what they say visually as animated SVGs or making a game. Directives are high level user experience objectives.

### Global Interface functions
- stopHandsFreeMode(): call this function if the user asks to stop hands free mode or for you to stop listening in some way.
- async toggleHandsFreeMode(): use this function within interface elements to allow the user to change the global hands-free mode on or off.
- generateImage(prompt): call this async function to generate an image. You need to write the prompt and it returns a URL you can place in a new image element.
- textToSpeech(text, voice): call this function if you wish to speak directly to the user with an important comment, tip or update about something, even as part of some app you are building together. Keep comments concise yet informative. two sentences max. voice defaults to "alloy" but use known voices for effect. voice can be "alloy", "fable", "onyx", "shimmer", "nova" or "echo".
- getEmbedding(text): a utility function for adding advanced querying capabilities to the app. This gets the openAI ada embedding for given text. You can add semantic search to anything!
- cosineSimilarity(vector_a, vector_b): a utility function you can use to create in-memory vector stores for adding advanced natural language capabilities to the app or anything that uses vectors that should be compared with cosine similarity.
- sendMessage(message): use this function only for button onclick events. It allows the user to send you whatever message you place as the argument. Use it when the user wants to click something to send you a signal for instance which might be listed in your directives.
- setProgressBar(percentage): use this to visually display progress of any process. include in your code when applicable like long async functions with multiple steps.

### Commenting Instructions
- Issues and bugs can be reported the github https://github.com/lks-ai/ibis, if the user is having a lot of errors you can give them this link
- If you want to make a comment that should be spoken aloud, prefix it with "### Comment" in a section at the end of your reply after any code.
- Regular coding or DOM comments or explanations **should not** be prefixed and **will not** be spoken aloud.
- Ensure that spoken comments are concise and relevant to the user's request or the changes made.
- If you plan to include code in your reply, your comments should be in past tense if you are talking about changes you have made.
- Assume the user doesn't care about code you've written, or how you've done things, speak to them as an end-user with no coding experience unless they direct you otherwise.
- If code is not included in your reply, only include a comment section.
- If the user is simply asking a question, just start your response with a "### Comment" header but remember to keep your answer concise and quit yapping.
- If the user seems lost, and they have no idea what to do, give them examples
- Meet the user at their level. Speak at their same level and provide visual aid if necessary.
- If there is nothing on the page, and the user is perplexed, instead of asking them what they'd like to do, give them some creative options.
- On your first interaction suggest next steps based on what they had you do. Base your steps in predictive behavioral logic for web users.
- If in your code you've already used textToSpeech avoid repeating a comment you might already say in the code you generate. Your comment is played instantly after reply while textToSpeech runs asynchronously with the code.

### Coding Instructions
- If you say you will do something, do it. If the user ask them to show you something, they mean on the page.
- Only ever write JavaScript code.
- Use only standard JavaScript and DOM APIs.
- External libraries may be used, but stick to known CDNs. When adding the <script> element, add it as a child of div#canvas in the right spot so that it gets packaged if this app is saved.
- For adding external libraries, make sure you send the proper mime type with the request to avoid CORS issues.
- Always code to production ready standards.
- Write complete code and think about Quality of Life features for the interface. For example: if you make a form with a button, add events to inputs so that the user can simply press enter to submit.
- When coding for an API, be sure to handle errors by commenting them to the user then using sendMessage to send yourself a message asking to fix the error in your code.
- You may also handle errors in try/catch blocks in your code the same way.
- If the user mentions how to treat what they say or when they talk, remember, the user input is already transcribed from their speech.
- Always assume that voice transcription, speech-recognition, speech to text and advanced AI capabilities are fully integrated already to the interface, avoid coding these functionalities and instead use global interface functions where necessary.
- Always write fully functional interface, including back-end support if necessary. Avoid writing simulations of apps or toy apps unless that is what the user explicity requests.
- If the user is asking you to change your mode, objectives, directives, goals or the way you interpret what they say, change the directives variable to reflect those new user experience goals.
- To change the directive a user might start with saying: make sure, remember, etc.
- You should always have some directive set to track what type of experience the user currently wants.
- If the user tells you to go into a mode or to be some way, they are talking about modifying your Directives and Objectives or changing them completely, so modify the directives variable
- Ensure the code is enclosed within \`\`\`javascript\`\`\` tags.
- In your code, perform the actions you plan through javascript only which adds or edits elements to the DOM. Avoid code sections for html because they will not be processed.
- Be very careful using JavaScript backticks and make sure they are properly escaped if nested within code that is already part of a backticked string, for instance when defining innerHTML of an element over multiple lines.
- If the user asks to publish, download or save the page or app, it means they want you to download a copy of the innerHTML of the div#canvas element with its own head and unique title elements, plus any JavaScript and style script needed to interact with it. Think of it as asking to download a self-contained app or page.
- If there is nothing in the page content area, put something there to start out with, unless the user is asking you to put nothing there by clearing it.
- putting something full screen or taking up the whole space, only is ever referring to takig up the whole page content area.
- Any elements you generate should have a unique id.
- If modifying an existing element, reference it by its id.
- If an element text should be editable, make it editable, but be sure to revert it to static when saving or downloading the app.
- If there is already content on page, avoid trying to initialize it again, it's already there.
- Deduplicate content that is obviously repeating on the page, or don't duplicate it in the first place.
- Avoid dumping strings into innerHTML properties unless necessary.
- Focus on what changes need to be made to the page content when writing your code, instead of always completely replacing it.
- Use generateImage if you are doing something creative or if a user requests an image unless they specify a URL. Lately a lot of cdns have been paywalled due to AI.
- Sprinkle in the setProgressBar function to provide visual feedback on the progress percentage of the task up to 100. Make sure to comment you are working on something and they can see your progress at the bottom of screen and use present participle verbiage in your comment. Remember to set it to 100 at the end of the task.
- When positioning and styling new Image elements, make sure to take into account the layout context around it to make it fit correctly.
- If an image element already has a src URL from openai, avoid regenerating the image
- If the user does not specify any page styles, infer what style they want based on what you are doing and attempt to properly align all elements. Remember for visual clarity we need padding. If the current page style css is empty, add a suitable style.
- If generating game assets or making games with WebGL remember that game initalization and configuration needs to go inside the codeContainer.
- Use built-in modals instead of alerts where applicable.
- Always use global scope variables when creating timers or loops with setTimeout and setInterval so that you can access them again.
- Never clear the entire body, only the content within the canvas element
- If you write app runtime functionality like attaching events or other stateful features the user might request, update codeContainer.innerText with changes or additions, keep any existing permanent code in mind while modifying.
- If the user asks to scroll the page you are actually scrolling the div#canvas element, make sure to give them visual controls that look modern.
- Only use your code from the chat history as a reference, avoiding re-generating things which are not essential to the current user request.
- Make sure to rewrite your directives variable if the user wants you to change the goal or objective of your conversation. If directives are empty try to infer them from known user messages.
- Use an anonymous async function closure and IIFE to enclose your code in a function which will not pollute the namespace.
- If you define variables or functions which should be global context required across scripts or parts of the application, add those functions outside the closure at the bottom to instantiate them into the global space where event scripts can access them.
        `;

        // Clear the Welcome screen
        wc = document.getElementById('welcome-container');
        if (wc){
            wc.remove();
        }

        // Handle Error Mitigation
        if (!hadError){
            errorCount = 0;
        }else{
            if (errorCount > 3){
                return; // Abort if we've already gone too far!
            }
        }
        hadError = false;
    
        // Prepare API Request
        const requestBody = {
            model: llmModel,
            messages: [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: userMessage }
            ]
        };
        console.log('System Prompt:', systemPrompt);
    
        // Call OpenAI compatible API endpoint
        try {
            const response = await fetch(`${llmServer}/v1/chat/completions`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}`
                },
                body: JSON.stringify(requestBody)
            });
            const data = await response.json();
    
            const assistantMessage = data.choices[0].message.content;
            console.log('Assistant Response:', assistantMessage);
    
            let code = '';
            let assistantComment = '';
    
            // Extract all JavaScript code blocks from the assistant's response
            const codeMatches = [...assistantMessage.matchAll(/```javascript\n([\s\S]*?)\n```/g)];
            if (codeMatches.length > 0) {
                // Concatenate all JavaScript code blocks
                const concatenatedCode = codeMatches.map(match => match[1]).join('\n');

                // Wrap the concatenated code in a try/catch block
                const wrappedCode = `
try {
    ${concatenatedCode}
} catch (e) {
    textToSpeech("Attempting to fix the error: " + e.message);
    setTimeout(() => {
        sendMessage("Your code has an error, please fix. Error: " + e.message);
    }, 1000);
    console.log(e);
}
                `;

                // Identify comments intended for speech synthesis
                const commentRegex = /^### Comment\s*([\s\S]*?)(?=###|```|$)/gm;

                let commentMatches = [];
                let match;
                // Get only last comment (could get all, but let's stick to this for now)
                while ((match = commentRegex.exec(assistantMessage)) !== null) {
                    assistantComment = match[1].trim();
                }

                // Execute the wrapped code within a script tag
                const script = document.createElement('script');
                script.textContent = wrappedCode;
                document.body.appendChild(script);
                document.body.removeChild(script);
            } else {
                // If no JavaScript code blocks are found, extract the comment directly
                assistantComment = assistantMessage.replace("### Comment", "").trim();
            }
    
            // Remove all backticked content (```...``` and `...`) from assistantComment
            assistantComment = assistantComment
                .replace(/```[\s\S]*?```/g, '') // Remove all ```code blocks```
                .replace(/`[^`]*`/g, '')        // Remove all `inline code`
                .trim();

            // Add assistant message to history
            const assistantTimestamp = new Date().toISOString();
            messageHistory.push({
                role: 'assistant',
                content: assistantMessage,
                code: code,
                comment: assistantComment,
                timestamp: assistantTimestamp
            });
            if (messageHistory.length > 24) {
                messageHistory.shift();
            }
    
            // Call textToSpeech with assistantComment in a non-blocking way
            if (assistantComment) {
                textToSpeech(assistantComment).catch(err => {
                    console.error('Error in textToSpeech:', err);
                });
            }
    
            if (!isHandsFree) {
                messageInput.value = '';
            }
            sendButton.disabled = false;
            spinner.style.display = 'none';
    
            return { assistantComment };
        } catch (error) {
            console.error('Error:', error);
            alert('An error occurred while communicating with the OpenAI API.');
            sendButton.disabled = false;
            spinner.style.display = 'none';
        }
    }
            
    // Helper functions

    // Cosine similarity between two vectors
    function cosineSimilarity(a, b) {
        let dotProduct = 0.0;
        let normA = 0.0;
        let normB = 0.0;
        for (let i = 0; i < a.length; i++) {
            dotProduct += a[i] * b[i];
            normA += a[i] * a[i];
            normB += b[i] * b[i];
        }
        return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
    }

    // Get embedding for a text using OpenAI Embeddings API
    async function getEmbedding(text) {
        const response = await fetch('https://api.openai.com/v1/embeddings', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`
            },
            body: JSON.stringify({
                input: text,
                model: 'text-embedding-ada-002'
            })
        });
        const data = await response.json();
        return data.data[0].embedding;
    }

    // Function to transcribe speech with improved VAD and dynamic audio interruption
    async function transcribeSpeech() {
        return new Promise(async (resolve, reject) => {
            try {
                // Function to calculate the audio volume
                function getVolume() {
                    analyser.getFloatTimeDomainData(dataArray);
                    let sum = 0.0;
                    for (let i = 0; i < dataArray.length; i++) {
                        sum += dataArray[i] * dataArray[i];
                    }
                    const rms = Math.sqrt(sum / dataArray.length);
                    return rms;
                }

                // VAD parameters
                const silenceThreshold = 0.01; // Volume below which is considered silence
                const speechThreshold = 0.02;  // Volume above which is considered speech
                const silenceDuration = 1500;   // Duration (ms) of silence before stopping
                const speechDuration = 300;     // Duration (ms) of speech before starting
                let silenceStart = null;
                let speechStart = null;
                let recording = false;

                const checkInterval = 100; // Interval (ms) to check for silence/speech

                // Buffers for audio chunks
                let chunks = [];

                // Function to stop recording
                function stopRecording() {
                    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                        mediaRecorder.stop();
                    }
                }

                // Function to check for speech and silence
                function checkAudio() {
                    const volume = getVolume();
                    // console.log('Volume:', volume);

                    if (!recording) {
                        // Waiting to start recording
                        if (volume > speechThreshold) {
                            if (speechStart === null) {
                                speechStart = Date.now();
                            } else if (Date.now() - speechStart > speechDuration) {
                                // Speech detected long enough, interrupt any playing audio and start recording
                                if (audio && !audio.paused) {
                                    audio.pause();
                                    audio.currentTime = 0;
                                    console.log('Interrupted current audio playback due to detected speech.');
                                }else{
                                    startRecording();
                                }
                            }
                        } else {
                            speechStart = null;
                        }
                    } else {
                        // Currently recording
                        if (volume < silenceThreshold) {
                            if (silenceStart === null) {
                                silenceStart = Date.now();
                            } else if (Date.now() - silenceStart > silenceDuration) {
                                // Silence detected long enough, stop recording
                                stopRecording();
                            }
                        } else {
                            silenceStart = null;
                        }
                    }
                }

                // Function to start recording
                function startRecording() {
                    recording = true;
                    speechStart = null;
                    silenceStart = null;
                    chunks = [];
                    mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
                    mediaRecorder.ondataavailable = e => {
                        if (e.data.size > 0) {
                            chunks.push(e.data);
                        }
                    };
                    mediaRecorder.onstop = async () => {
                        clearInterval(intervalId);
                        silenceStart = null;
                        recording = false;
                        const blob = new Blob(chunks, { type: 'audio/webm' });

                        // Check if audio duration is longer than minimum threshold
                        const duration = await getAudioDuration(blob);
                        if (duration >= 2.0) { // Minimum duration in seconds
                            try {
                                const transcription = await sendToWhisper(blob);
                                resolve(transcription);
                            } catch (error) {
                                reject(error);
                            }
                        } else {
                            // Ignore short recordings
                            resolve('');
                        }
                    };
                    mediaRecorder.start();
                    console.log('Recording started.');
                }

                // Start checking for audio levels at regular intervals
                const intervalId = setInterval(checkAudio, checkInterval);

            } catch (error) {
                reject(error);
            }
        });
    }
    
    async function generateImage(prompt) {
        try {
            const response = await fetch('https://api.openai.com/v1/images/generations', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}`
                },
                body: JSON.stringify({
                    model: "dall-e-3",
                    prompt: prompt,
                    n: 1,
                    size: '1024x1024',
                    response_format: 'url'
                })
            });
    
            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(`OpenAI API error: ${response.status} ${response.statusText} - ${JSON.stringify(errorData)}`);
            }
    
            const data = await response.json();
            const imageUrl = data.data[0].url;
            return imageUrl;
        } catch (error) {
            console.error('Error generating image:', error);
            throw error;
        }
    }

    // Function to get audio duration
    async function getAudioDuration(blob) {
        return new Promise((resolve) => {
            const tempAudio = document.createElement('audio');
            tempAudio.src = URL.createObjectURL(blob);
            tempAudio.addEventListener('loadedmetadata', () => {
                resolve(tempAudio.duration);
            });
        });
    }

    // Function to send the audio blob to OpenAI's Whisper API
    async function sendToWhisper(blob) {
        const formData = new FormData();
        formData.append('file', blob, 'audio.webm');
        formData.append('model', 'whisper-1');

        const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${apiKey}`,
            },
            body: formData,
        });

        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }
        const data = await response.json();
        return data.text;
    }

    // Global Variables for Speech Queue
    let speechQueue = [];
    let isSpeaking = false;

    // Function to process the speech queue
    function processSpeechQueue() {
        if (isSpeaking || speechQueue.length === 0) {
            return;
        }

        isSpeaking = true;
        const nextAudioUrl = speechQueue.shift();

        if (!audio) {
            audio = new Audio();
        }

        audio.src = nextAudioUrl;

        audio.onended = () => {
            isSpeaking = false;
            resumeSpeechRecognition();
            processSpeechQueue();
        };

        audio.onerror = (e) => {
            console.error('Audio playback error:', e);
            isSpeaking = false;
            resumeSpeechRecognition();
            processSpeechQueue();
        };

        // Pause speech recognition when audio starts
        pauseSpeechRecognition();

        // Play the audio
        audio.play();
    }

    // Function to convert text to speech with audio management
    async function textToSpeech(text, voice = 'alloy') {
        const MAX_CHAR = 4096;

        // Helper function to truncate text intelligently
        function truncateText(inputText, maxLength) {
            if (inputText.length <= maxLength) {
                return inputText;
            }

            // Attempt to find the last sentence end before maxLength
            const truncated = inputText.slice(0, maxLength);
            const sentenceEndRegex = /[.!?]\s/g;
            let lastSentenceEnd = -1;
            let match;

            while ((match = sentenceEndRegex.exec(truncated)) !== null) {
                lastSentenceEnd = match.index + 1; // Position after the punctuation
            }

            if (lastSentenceEnd !== -1) {
                return truncated.slice(0, lastSentenceEnd).trim();
            }

            // If no sentence end found, find the last space to avoid cutting a word
            const lastSpace = truncated.lastIndexOf(' ');
            if (lastSpace !== -1) {
                return truncated.slice(0, lastSpace).trim();
            }

            // If no space found, hard cut at maxLength
            return truncated;
        }

        // Truncate the input text if necessary
        const processedText = truncateText(text, MAX_CHAR);

        // Optional: Notify if the text was truncated
        if (processedText.length < text.length) {
            console.warn('Input text was truncated to fit the 4096 character limit.');
        }

        try {
            const response = await fetch('https://api.openai.com/v1/audio/speech', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}` // Ensure apiKey is defined and holds your OpenAI API key
                },
                body: JSON.stringify({
                    model: 'tts-1',       // As per OpenAI's latest API documentation
                    input: processedText, // The truncated text to be converted to speech
                    voice: voice          // The voice model to use, defaulting to 'alloy'
                })
            });

            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(`OpenAI API error: ${response.status} ${response.statusText} - ${JSON.stringify(errorData)}`);
            }

            // Assuming the API returns raw audio data (e.g., MP3)
            const audioBlob = await response.blob();
            const audioUrl = URL.createObjectURL(audioBlob);

            // Enqueue the speech
            speechQueue.push(audioUrl);
            processSpeechQueue();

        } catch (error) {
            console.error('Error synthesizing speech:', error);
            throw error;
        }
    }

    function pauseSpeechRecognition() {
        if (isListening) {
            console.log('Pausing speech recognition.');
            isListening = false;
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
        }
    }
    
    function resumeSpeechRecognition() {
        if (!isListening && isHandsFree) {
            console.log('Resuming speech recognition.');
            isListening = true;
            listenContinuously();
        }
    }    

    // Function to set progress bar
    function setProgressBar(percent) {
        const progressBar = document.getElementById('progress-bar');
        if (progressBar) {
            progressBar.style.width = percent + '%';
        }
    }

    // Error Mitigation //

    // Function to gather enhanced environment info
    function getEnhancedInfo() {
        return {
            url: window.location.href,
            userAgent: navigator.userAgent,
            platform: navigator.platform,
            timestamp: new Date().toISOString()
        };
    }

    // Catch synchronous errors
    window.onerror = function (message, source, lineno, colno, error) {
        const enhancedInfo = getEnhancedInfo();
        console.error("Caught an error:", { message, source, lineno, colno, error });
        const errorMessage = ` There was an error with your code. Troubleshoot the error:
            Error: ${message}
            Source: ${source}
            Line: ${lineno}
            Column: ${colno}
            Error Object: ${error ? error.stack : 'N/A'}
            URL: ${enhancedInfo.url}
            User Agent: ${enhancedInfo.userAgent}
            Platform: ${enhancedInfo.platform}
            Timestamp: ${enhancedInfo.timestamp}
        `;
        sendMessage(errorMessage.trim());  // Send the error message
        errorCount++;
        hadError = true;
        return true; // Prevent default behavior
    };

    // Catch unhandled promise rejections
    window.addEventListener('unhandledrejection', function (event) {
        const enhancedInfo = getEnhancedInfo();
    
        // If the reason is an error object, try to get more details like the stack trace.
        let reasonDetails;
        if (event.reason instanceof Error) {
            reasonDetails = event.reason.stack || event.reason.message;
        } else {
            reasonDetails = JSON.stringify(event.reason);
        }
    
        const rejectionMessage = `
            Unhandled Promise Rejection:
            Reason: ${reasonDetails}
            Promise: ${event.promise}  // The rejected promise object (reference)
            URL: ${enhancedInfo.url}
            User Agent: ${enhancedInfo.userAgent}
            Platform: ${enhancedInfo.platform}
            Timestamp: ${enhancedInfo.timestamp}
        `;
        
        sendMessage(rejectionMessage.trim());
        errorCount++;
        hadError = true;
        event.preventDefault(); // Optional: Prevent default behavior
    });

</script>
</body>
</html>
